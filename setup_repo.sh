#!/bin/bash

# GitHub Repository Setup for ALCIE User Study
# Run this inside your cloned repository directory

echo "🚀 Setting up ALCIE User Study Repository..."

# Create directory structure
mkdir -p data
mkdir -p src
mkdir -p docs
mkdir -p results

# Copy your dataset
echo "📁 Copying dataset..."
cp /home/akkumar/ALCIE/user_study/alcie_diverse_dataset.json data/

# Create requirements.txt
echo "📦 Creating requirements.txt..."
cat > requirements.txt << EOF
streamlit>=1.28.0
pandas>=1.5.0
numpy>=1.24.0
pillow>=9.0.0
plotly>=5.15.0
jsonschema>=4.17.0
requests>=2.28.0
EOF

echo "📝 Creating README.md..."
cat > README.md << 'EOF'
# ALCIE User Study: Catastrophic Forgetting in Fashion Caption Generation

This repository contains the human evaluation study for analyzing catastrophic forgetting effects in fashion image captioning models trained with different sampling strategies.

## 🎯 Study Overview

- **Research Question**: How do different training data sampling methods (random, diversity, uncertainty) affect caption quality and catastrophic forgetting?
- **Dataset**: 24 carefully selected fashion images across 6 categories
- **Methods**: Random, Diversity, and Uncertainty sampling
- **Evaluation**: Human preference ratings and quality assessments

## 📊 Study Design

### Categories & Catastrophic Forgetting Risk
- **Phase 1 - Accessories** (6 samples): Highest CF risk
- **Phase 2 - Bottoms** (5 samples): Very high CF risk  
- **Phase 3 - Dresses** (4 samples): High CF risk
- **Phase 4 - Outerwear** (3 samples): Medium CF risk
- **Phase 5 - Shoes** (3 samples): Low CF risk
- **Phase 6 - Tops** (3 samples): Lowest CF risk

## 🚀 Running the Study

### Local Development
```bash
pip install -r requirements.txt
streamlit run src/alcie_study_app.py
```

### Streamlit Cloud Deployment
This app is deployed at: [Your Streamlit URL will appear here]

## 📁 Repository Structure

```
alcie-user-study/
├── data/
│   └── alcie_diverse_dataset.json    # Study dataset
├── src/
│   └── alcie_study_app.py           # Streamlit application
├── docs/
│   └── study_protocol.md            # Detailed study protocol
├── results/
│   └── (study results will be saved here)
├── requirements.txt                  # Python dependencies
└── README.md                        # This file
```

## 🔬 Research Context

This study is part of research on catastrophic forgetting in continual learning for fashion image captioning. The goal is to understand how different training data sampling strategies affect model performance across sequential learning phases.

## 📈 Expected Outcomes

- Quantitative analysis of caption quality across categories
- Detection of catastrophic forgetting patterns
- Comparison of sampling method effectiveness
- Insights for improving continual learning in fashion AI

## 📞 Contact

For questions about this study, please contact: [Your email]

## 📄 Citation

If you use this dataset or findings from this study, please cite:
```bibtex
[Your citation will go here]
```
EOF

echo "📋 Creating study protocol..."
cat > docs/study_protocol.md << 'EOF'
# ALCIE User Study Protocol

## Participant Instructions

### Overview
You will evaluate fashion image captions generated by three different AI models. Your task is to rate the quality and accuracy of captions for fashion items.

### Study Process

1. **View Fashion Image**: You'll see a fashion item (bag, dress, shoes, etc.)
2. **Read Three Captions**: Each generated by a different AI model
3. **Rate Each Caption**: Score 1-5 based on:
   - Accuracy of description
   - Completeness of details
   - Natural language quality
   - Overall usefulness
4. **Repeat**: 24 images total (approximately 15-20 minutes)

### Rating Scale

- **5 - Excellent**: Perfect description, natural language, comprehensive details
- **4 - Good**: Accurate with minor issues, mostly complete
- **3 - Fair**: Generally accurate but missing details or awkward phrasing
- **2 - Poor**: Some accuracy but significant issues
- **1 - Very Poor**: Inaccurate, incomplete, or incomprehensible

### Tips for Good Evaluation

- Focus on **accuracy** - does the caption match what you see?
- Consider **completeness** - are important details included?
- Evaluate **naturalness** - does it sound like human-written text?
- Be **consistent** in your rating criteria across all images

### Technical Details

- **Time Commitment**: 15-20 minutes
- **Images**: 24 fashion items
- **Categories**: Accessories, Bottoms, Dresses, Outerwear, Shoes, Tops
- **Anonymized**: You won't know which model generated which caption

Thank you for contributing to fashion AI research! 🎯
EOF

# Create .gitignore
echo "🚫 Creating .gitignore..."
cat > .gitignore << EOF
# Python
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
.venv/
pip-log.txt
pip-delete-this-directory.txt

# Streamlit
.streamlit/

# OS
.DS_Store
Thumbs.db

# IDE
.vscode/
.idea/
*.swp
*.swo

# Results (if containing sensitive data)
results/raw_responses/
*.csv
*.xlsx

# Logs
*.log
EOF

echo "✅ Repository structure created!"
echo ""
echo "📁 Directory structure:"
find . -type f -name "*.md" -o -name "*.txt" -o -name "*.json" -o -name "*.py" | head -20
echo ""
echo "🎯 Next steps:"
echo "1. Copy your Streamlit app to src/alcie_study_app.py"
echo "2. Add and commit files: git add . && git commit -m 'Initial setup'"
echo "3. Push to GitHub: git push origin main"
echo "4. Deploy on Streamlit Cloud"
